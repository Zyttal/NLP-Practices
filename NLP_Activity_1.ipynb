{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0w8LLelaoNN"
      },
      "source": [
        "# Applying Tokenization via NLTK & Own Implementation\n",
        "\n",
        "---\n",
        "\n",
        "- AKA Natural Language Toolkit\n",
        "- Free and Open source Python Library for Natural Language Processing\n",
        "- For this Activity, Tokenization is done\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "D5biWyuyZgUn"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'nltk'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7yj2JO7wj8l"
      },
      "source": [
        "# White-Space (Unigram)\n",
        "---\n",
        "- Breaking down Text into individual words based on the presence of white space characters\n",
        "\n",
        "# Use Case\n",
        "- Aids in understanding Individual words and their frequencies in a corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrXOrZZlwLyH",
        "outputId": "7cc86960-39dd-4f05-ff8c-393cd7ef513c"
      },
      "outputs": [],
      "source": [
        "sentence = \"Hello World! This is a test code.\"\n",
        "\n",
        "unigrams = sentence.strip().split()\n",
        "print(unigrams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApSZByGpP6BJ",
        "outputId": "73a15c66-a910-48d6-d25d-0cf71c1b6aea"
      },
      "outputs": [],
      "source": [
        "sentence = \"Hello World! This is a test code.\"\n",
        "\n",
        "unigrams = sentence.split()\n",
        "print(unigrams)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2UKjudywlEx"
      },
      "source": [
        "# Bigram\n",
        "---\n",
        "- AKA 2-gram\n",
        "- A sequence of two adjacent words\n",
        "- captures the co-occurrence patters of words in a text\n",
        "\n",
        "# Use Case\n",
        "- autocorrect\n",
        "- autocompletion\n",
        "- text summarization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWUyDxjdwN9G",
        "outputId": "c3876a2b-e0da-4694-9469-15cfde996c4b"
      },
      "outputs": [],
      "source": [
        "sentence = \"Hello World! This is a test code.\"\n",
        "\n",
        "bigrams = list(nltk.bigrams(sentence.split()))\n",
        "print(bigrams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWQctotRQjbN",
        "outputId": "428dc8cf-547f-4564-d79a-711cda4adc74"
      },
      "outputs": [],
      "source": [
        "sentence = \"Hello World! This is a test code.\"\n",
        "\n",
        "words = sentence.split()\n",
        "bigrams = [(words[x], words[x + 1]) for x in range(len(words) - 1)]\n",
        "print(bigrams)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xI_640ivwwX6"
      },
      "source": [
        "# Trigram\n",
        "\n",
        "---\n",
        "\n",
        "- AKA 3-gram\n",
        "- A sequence of three adjacent words\n",
        "- Provides more context than bigrams\n",
        "\n",
        "# Use Case\n",
        "- Helps identify a text's topic\n",
        "- Generate new text similar to existing content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXeEL1Dfw2EL",
        "outputId": "c781d888-953f-41ff-b2ac-93513023ba6d"
      },
      "outputs": [],
      "source": [
        "sentence = \"Hello World! This is a test code.\"\n",
        "\n",
        "trigrams = list(nltk.trigrams(sentence.split()))\n",
        "print(trigrams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKpHGNajQtMp",
        "outputId": "6d4b9672-03f5-4584-f468-5d370e9743c5"
      },
      "outputs": [],
      "source": [
        "sentence = \"Hello World! This is a test code.\"\n",
        "\n",
        "words = sentence.split()\n",
        "trigrams = [(words[x], words[x + 1], words[x + 2]) for x in range(len(words) - 2)]\n",
        "print(trigrams)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjXjthZLwymK"
      },
      "source": [
        "# Regex\n",
        "---\n",
        "- For pattern matching and string manipulation to filter out unnecessary texts\n",
        "\n",
        "# Use Case\n",
        "- searching\n",
        "- extracting\n",
        "- replacing text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJ-Sz8S5w3NA",
        "outputId": "5b2a2bef-2aba-47e5-eafe-ba15b5dd7dbe"
      },
      "outputs": [],
      "source": [
        "sentence = \"Please contact me at john.doe@example.com or support@company.com\"\n",
        "\n",
        "email_pattern = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n",
        "emails = re.findall(email_pattern, sentence)\n",
        "\n",
        "print(\"Extracted email addresses:\")\n",
        "for email in emails:\n",
        "  print(email)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
